{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import io\n",
    "import json\n",
    "from rouge import Rouge\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edmundson Summary:\n",
      "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans using natural language.\n",
      "NLP combines computational linguistics, rule-based modeling of human language, and machine learning to build models that can process large amounts of natural language data.\n",
      "Ethical concerns also arise, as NLP systems may perpetuate biases present in the training data.\n",
      "\n",
      "LSA Summary:\n",
      "Word embeddings like Word2Vec, GloVe, and FastText create dense vector representations of words that capture semantic relationships between them.\n",
      "Ethical concerns also arise, as NLP systems may perpetuate biases present in the training data.\n",
      "Nevertheless, NLP is transforming industries by enabling machines to interact with humans in more intuitive and effective ways.\n",
      "\n",
      "KL Summary:\n",
      "The goal is to enable machines to understand, interpret, and generate human language in a way that is meaningful and useful.\n",
      "Language modeling plays a key role in predicting the next word or phrase in a sentence based on the previous words, and this underpins many NLP applications like text generation, speech recognition, and machine translation.\n",
      "Transformers, like BERT and GPT, are neural networks that excel at understanding complex language patterns and are used in tasks such as text generation, sentiment analysis, and machine translation.\n",
      "\n",
      "LexRank Summary:\n",
      "Language modeling plays a key role in predicting the next word or phrase in a sentence based on the previous words, and this underpins many NLP applications like text generation, speech recognition, and machine translation.\n",
      "Question answering systems are designed to answer human questions based on contextual understanding of text, and they are seen in applications such as search engines and virtual assistants.\n",
      "Transformers, like BERT and GPT, are neural networks that excel at understanding complex language patterns and are used in tasks such as text generation, sentiment analysis, and machine translation.\n",
      "\n",
      "File Summaries:\n",
      "\n",
      "Edmundson Summary:\n",
      "Natural language processing is a subfield of artificial intelligence (AI) focused on the interaction between computers and humans through natural language.\n",
      "The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.\n",
      "NLP is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\n",
      "\n",
      "LSA Summary:\n",
      "Natural language processing is a subfield of artificial intelligence (AI) focused on the interaction between computers and humans through natural language.\n",
      "The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.\n",
      "NLP is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\n",
      "\n",
      "KL Summary:\n",
      "Natural language processing is a subfield of artificial intelligence (AI) focused on the interaction between computers and humans through natural language.\n",
      "The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.\n",
      "NLP is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\n",
      "\n",
      "LexRank Summary:\n",
      "Natural language processing is a subfield of artificial intelligence (AI) focused on the interaction between computers and humans through natural language.\n",
      "The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.\n",
      "NLP is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\n",
      "\n",
      "URL Summaries:\n",
      "\n",
      "Edmundson Summary:\n",
      "{\\displaystyle {RMM(token_{N})}={PMM(token_{N})}\\times {\\frac {1}{2d}}\\left(\\sum _{i=-d}^{d}{((PMM(token_{N})}\\times {PF(token_{N-i},token_{N},token_{N+i}))_{i}}\\right)}\n",
      "1 the Road Artificial intelligence detection software Automated essay scoring Biomedical text mining Compound term processing Computational linguistics Computer-assisted reviewing Controlled natural language Deep learning Deep linguistic processing Distributional semantics Foreign language reading aid Foreign language writing aid Information extraction Information retrieval Language and Communication Technologies Language model Language technology Latent semantic indexing Multi-agent system Native-language identification Natural-language programming Natural-language understanding Natural-language search Outline of natural language processing Query expansion Query understanding Reification (linguistics) Speech processing Spoken dialogue systems Text-proofing Text simplification Transformer (machine learning model) Truecasing Question answering Word2vec\n",
      "External links[edit] Media related to Natural language processing at Wikimedia Commons vteNatural language processingGeneral terms AI-complete Bag-of-words n-gram Bigram Trigram Computational linguistics Natural language understanding Stop words Text processing Text analysis Argument mining Collocation extraction Concept mining Coreference resolution Deep linguistic processing Distant reading Information extraction Named-entity recognition Ontology learning Parsing Semantic parsing Syntactic parsing Part-of-speech tagging Semantic analysis Semantic role labeling Semantic decomposition Semantic similarity Sentiment analysis Terminology extraction Text mining Textual entailment Truecasing Word-sense disambiguation Word-sense induction Text segmentation Compound-term processing Lemmatisation Lexical analysis Text chunking Stemming Sentence segmentation Word segmentation\n",
      "\n",
      "LSA Summary:\n",
      "Discourse (semantics beyond individual sentences)[edit] Coreference resolution Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\").\n",
      "Natural-language understanding (NLU) Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate.\n",
      "^ Yi, Chucai; Tian, Yingli (2012), \"Assistive Text Reading from Complex Background for Blind Persons\", Camera-Based Document Analysis and Recognition, Lecture Notes in Computer Science, vol.\n",
      "\n",
      "KL Summary:\n",
      "Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.\n",
      "Common NLP tasks[edit] The following is a list of some of the most commonly researched tasks in natural language processing.\n",
      "The difficulty of this task depends greatly on the complexity of the morphology (i.e., the structure of words) of the language being considered.\n",
      "\n",
      "LexRank Summary:\n",
      "Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.\n",
      "However, some written languages like Chinese, Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language.\n",
      "Where RMM is the relative measure of meaning token is any block of text, sentence, phrase or word N is the number of tokens being analyzed PMM is the probable measure of meaning based on a corpora d is the non zero location of the token along the sequence of N tokens PF is the probability function specific to a language Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s.\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(text, num_sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    \n",
    "    summarizers = {\n",
    "        \"Edmundson\": EdmundsonSummarizer(),\n",
    "        \"LSA\": LsaSummarizer(),\n",
    "        \"KL\": KLSummarizer(),\n",
    "        \"LexRank\": LexRankSummarizer()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, summarizer in summarizers.items():\n",
    "        if name == \"Edmundson\":\n",
    "            summarizer.bonus_words = [\"NLP\", \"language\", \"algorithms\", \"AI\", \"natural\"]\n",
    "            summarizer.stigma_words = [\"is\", \"the\", \"a\", \"of\", \"and\", \"to\", \"in\"]\n",
    "            summarizer.null_words = [\"and\", \"or\", \"but\", \"if\", \"then\", \"with\", \"so\", \"on\"]\n",
    "        \n",
    "        summary = summarizer(parser.document, num_sentences)\n",
    "        results[name] = \"\\n\".join(str(sentence) for sentence in summary)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize from a file\n",
    "def summarize_from_file(file_path, num_sentences=3):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return summarize_text(text, num_sentences)\n",
    "\n",
    "def summarize_from_url(url, num_sentences=3):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return summarize_text(text, num_sentences)\n",
    "\n",
    "# Example usage\n",
    "document = \"\"\"\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans using natural language. The goal is to enable machines to understand, interpret, and generate human language in a way that is meaningful and useful. NLP combines computational linguistics, rule-based modeling of human language, and machine learning to build models that can process large amounts of natural language data. The primary tasks in NLP range from basic text preprocessing to more complex tasks like language generation and understanding. Text preprocessing involves cleaning and preparing the text for analysis, breaking it into manageable units through tokenization, stemming, lemmatization, stopword removal, and part-of-speech tagging. Once text is preprocessed, syntactic and semantic analysis techniques help machines understand the structure and meaning of sentences, including parsing, dependency parsing, named entity recognition, and word sense disambiguation. Language modeling plays a key role in predicting the next word or phrase in a sentence based on the previous words, and this underpins many NLP applications like text generation, speech recognition, and machine translation. Sentiment analysis identifies the sentiment expressed in a text and is widely used in social media monitoring and customer feedback systems. Automatic text summarization reduces large pieces of text to shorter versions while retaining key information, which can be done through extractive summarization (selecting important sentences or phrases) or abstractive summarization (generating a summary in its own words). Question answering systems are designed to answer human questions based on contextual understanding of text, and they are seen in applications such as search engines and virtual assistants. NLP techniques and models have evolved significantly with the rise of deep learning. Bag of Words is a basic technique for converting text into numerical data, while TF-IDF builds on this by weighting words based on their importance in the text corpus. Word embeddings like Word2Vec, GloVe, and FastText create dense vector representations of words that capture semantic relationships between them. However, the real revolution in NLP came with the introduction of Transformer models. Transformers, like BERT and GPT, are neural networks that excel at understanding complex language patterns and are used in tasks such as text generation, sentiment analysis, and machine translation. Recurrent neural networks (RNNs) and Long Short-Term Memory (LSTM) models were previously dominant for sequence-based NLP tasks but have been largely replaced by Transformer architectures due to their superior ability to capture long-range dependencies in text. NLP is used in a wide variety of applications, from search engines and chatbots to healthcare, legal document analysis, and financial services. Despite these advances, NLP faces challenges such as the inherent ambiguity of human language, the diversity of languages and dialects, and the need for better understanding of context in conversations. Ethical concerns also arise, as NLP systems may perpetuate biases present in the training data. Nevertheless, NLP is transforming industries by enabling machines to interact with humans in more intuitive and effective ways.\n",
    "\"\"\"\n",
    "\n",
    "summaries = summarize_text(document)\n",
    "\n",
    "for name, summary in summaries.items():\n",
    "    print(f\"\\n{name} Summary:\")\n",
    "    print(summary)\n",
    "\n",
    "# Example usage for file and URL\n",
    "file_path = \"/home/t/Desktop/koulu/nltk/proj/test.in\"\n",
    "file_summaries = summarize_from_file(file_path)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "url_summaries = summarize_from_url(url)\n",
    "\n",
    "print(\"\\nFile Summaries:\")\n",
    "for name, summary in file_summaries.items():\n",
    "    print(f\"\\n{name} Summary:\")\n",
    "    print(summary)\n",
    "\n",
    "print(\"\\nURL Summaries:\")\n",
    "for name, summary in url_summaries.items():\n",
    "    print(f\"\\n{name} Summary:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 samples from the dataset.\n",
      "Evaluating Edmundson summarizer...\n",
      "Evaluating LSA summarizer...\n",
      "Evaluating KL summarizer...\n",
      "Evaluating LexRank summarizer...\n",
      "Edmundson Summarizer:\n",
      "  ROUGE-1: 0.6595\n",
      "  ROUGE-2: 0.6000\n",
      "  ROUGE-L: 0.6587\n",
      "\n",
      "LSA Summarizer:\n",
      "  ROUGE-1: 0.4125\n",
      "  ROUGE-2: 0.3041\n",
      "  ROUGE-L: 0.3991\n",
      "\n",
      "KL Summarizer:\n",
      "  ROUGE-1: 0.4443\n",
      "  ROUGE-2: 0.3397\n",
      "  ROUGE-L: 0.4361\n",
      "\n",
      "LexRank Summarizer:\n",
      "  ROUGE-1: 0.5529\n",
      "  ROUGE-2: 0.4660\n",
      "  ROUGE-L: 0.5457\n",
      "\n",
      "Analysis:\n",
      "1. Performance Comparison:\n",
      "   - Best ROUGE-1 performance: Edmundson\n",
      "   - Best ROUGE-2 performance: Edmundson\n",
      "   - Best ROUGE-L performance: Edmundson\n"
     ]
    }
   ],
   "source": [
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Initialize summarizers\n",
    "edmundson = EdmundsonSummarizer()\n",
    "edmundson.bonus_words = [\"important\", \"significant\", \"key\", \"central\", \"crucial\"]\n",
    "edmundson.stigma_words = [\"trivial\", \"minor\", \"unimportant\", \"insignificant\"]\n",
    "edmundson.null_words = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"of\", \"with\"]\n",
    "\n",
    "summarizers = {\n",
    "    \"Edmundson\": edmundson,\n",
    "    \"LSA\": LsaSummarizer(),\n",
    "    \"KL\": KLSummarizer(),\n",
    "    \"LexRank\": LexRankSummarizer()\n",
    "}\n",
    "\n",
    "def generate_summary(text, summarizer, num_sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "def evaluate_summarizer(summarizer, data):\n",
    "    rouge_1_scores = []\n",
    "    rouge_2_scores = []\n",
    "    rouge_l_scores = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        full_text = row['summary']\n",
    "        reference_summary = row['title'] + \". \" + \" \".join(full_text.split()[:30])  # Use title and first 30 words as reference\n",
    "        generated_summary = generate_summary(full_text, summarizer)\n",
    "        \n",
    "        scores = rouge.get_scores(generated_summary, reference_summary)[0]\n",
    "        rouge_1_scores.append(scores['rouge-1']['f'])\n",
    "        rouge_2_scores.append(scores['rouge-2']['f'])\n",
    "        rouge_l_scores.append(scores['rouge-l']['f'])\n",
    "    \n",
    "    return np.mean(rouge_1_scores), np.mean(rouge_2_scores), np.mean(rouge_l_scores)\n",
    "\n",
    "# Load the Wikipedia Summary Dataset\n",
    "def load_wiki_summary_data(file_path, num_samples=10000):\n",
    "    with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "        txt_file = [f for f in tar.getmembers() if f.name.endswith('.txt')][0]\n",
    "        with tar.extractfile(txt_file) as f:\n",
    "            content = io.TextIOWrapper(f, encoding='utf-8')\n",
    "            data = []\n",
    "            for i, line in enumerate(content):\n",
    "                if i >= num_samples:\n",
    "                    break\n",
    "                title, summary = line.strip().split('|||')\n",
    "                data.append({'title': title.strip(), 'summary': summary.strip()})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load the dataset\n",
    "data = load_wiki_summary_data('raw.tar.gz', num_samples=10000)\n",
    "print(f\"Loaded {len(data)} samples from the dataset.\")\n",
    "\n",
    "# Evaluate each summarizer\n",
    "results = {}\n",
    "for name, summarizer in summarizers.items():\n",
    "    print(f\"Evaluating {name} summarizer...\")\n",
    "    rouge_1, rouge_2, rouge_l = evaluate_summarizer(summarizer, data)\n",
    "    results[name] = {'ROUGE-1': rouge_1, 'ROUGE-2': rouge_2, 'ROUGE-L': rouge_l}\n",
    "\n",
    "# Print results\n",
    "for name, scores in results.items():\n",
    "    print(f\"{name} Summarizer:\")\n",
    "    print(f\"  ROUGE-1: {scores['ROUGE-1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {scores['ROUGE-2']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {scores['ROUGE-L']:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Analysis and comments\n",
    "print(\"Analysis:\")\n",
    "print(\"1. Performance Comparison:\")\n",
    "best_rouge1 = max(results, key=lambda x: results[x]['ROUGE-1'])\n",
    "best_rouge2 = max(results, key=lambda x: results[x]['ROUGE-2'])\n",
    "best_rougel = max(results, key=lambda x: results[x]['ROUGE-L'])\n",
    "print(f\"   - Best ROUGE-1 performance: {best_rouge1}\")\n",
    "print(f\"   - Best ROUGE-2 performance: {best_rouge2}\")\n",
    "print(f\"   - Best ROUGE-L performance: {best_rougel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Edmundson summarizer...\n",
      "\n",
      "Evaluating LSA summarizer...\n",
      "\n",
      "Evaluating KL summarizer...\n",
      "\n",
      "Evaluating LexRank summarizer...\n",
      "\n",
      "Edmundson Summarizer:\n",
      "  ROUGE-2: 0.1800\n",
      "  ROUGE-L: 0.3912\n",
      "\n",
      "LSA Summarizer:\n",
      "  ROUGE-2: 0.0359\n",
      "  ROUGE-L: 0.2256\n",
      "\n",
      "KL Summarizer:\n",
      "  ROUGE-2: 0.1868\n",
      "  ROUGE-L: 0.3711\n",
      "\n",
      "LexRank Summarizer:\n",
      "  ROUGE-2: 0.1868\n",
      "  ROUGE-L: 0.3711\n",
      "\n",
      "Analysis:\n",
      "1. Performance Comparison:\n",
      "   - Best ROUGE-2 performance: KL\n",
      "   - Best ROUGE-L performance: Edmundson\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key='your-api-key-here')\n",
    "\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Initialize summarizers\n",
    "edmundson = EdmundsonSummarizer()\n",
    "edmundson.bonus_words = [\"NLP\", \"language\", \"algorithms\", \"AI\", \"natural\"]\n",
    "edmundson.stigma_words = [\"is\", \"the\", \"a\", \"of\", \"and\", \"to\", \"in\"]\n",
    "edmundson.null_words = [\"and\", \"or\", \"but\", \"if\", \"then\", \"with\", \"so\", \"on\"]\n",
    "\n",
    "summarizers = {\n",
    "    \"Edmundson\": edmundson,\n",
    "    \"LSA\": LsaSummarizer(),\n",
    "    \"KL\": KLSummarizer(),\n",
    "    \"LexRank\": LexRankSummarizer()\n",
    "}\n",
    "\n",
    "def generate_gpt_summary(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following text in a few sentences: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def generate_summary(text, summarizer, num_sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "def evaluate_summarizer(summarizer, text, gpt_summaries):\n",
    "    rouge_2_scores = []\n",
    "    rouge_l_scores = []\n",
    "    \n",
    "    generated_summary = generate_summary(text, summarizer)\n",
    "    \n",
    "    for gpt_summary in gpt_summaries:\n",
    "        scores = rouge.get_scores(generated_summary, gpt_summary)[0]\n",
    "        rouge_2_scores.append(scores['rouge-2']['f'])\n",
    "        rouge_l_scores.append(scores['rouge-l']['f'])\n",
    "    \n",
    "    return np.mean(rouge_2_scores), np.mean(rouge_l_scores)\n",
    "\n",
    "# Your document\n",
    "document = \"\"\"\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans using natural language. The goal is to enable machines to understand, interpret, and generate human language in a way that is meaningful and useful. NLP combines computational linguistics, rule-based modeling of human language, and machine learning to build models that can process large amounts of natural language data. The primary tasks in NLP range from basic text preprocessing to more complex tasks like language generation and understanding. Text preprocessing involves cleaning and preparing the text for analysis, breaking it into manageable units through tokenization, stemming, lemmatization, stopword removal, and part-of-speech tagging. Once text is preprocessed, syntactic and semantic analysis techniques help machines understand the structure and meaning of sentences, including parsing, dependency parsing, named entity recognition, and word sense disambiguation. Language modeling plays a key role in predicting the next word or phrase in a sentence based on the previous words, and this underpins many NLP applications like text generation, speech recognition, and machine translation.\n",
    "\"\"\"\n",
    "\n",
    "# Use the GPT summaries you've already generated\n",
    "gpt_summaries = [\n",
    "    \"Natural Language Processing (NLP) is a branch of artificial intelligence focusing on computer-human interaction through language. It aims to help machines understand, interpret, and produce human language effectively. NLP involves tasks such as text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, text summarization, and question answering. Evolution in NLP includes the shift from traditional methods like Bag of Words and TF-IDF to advanced techniques such as Word embeddings and Transformer models like BERT and GPT. NLP has diverse applications ranging from search engines to healthcare and poses challenges like language diversity and biases in training data. Despite these challenges, NLP is revolutionizing industries by enhancing human-machine communication.\"\n",
    "    \"Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language. It combines computational linguistics and machine learning to process natural language data, from basic preprocessing to complex tasks like language generation and understanding. NLP tasks include text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, text summarization, and question answering systems. Recent developments in deep learning have advanced NLP techniques, with Transformer models like BERT and GPT outperforming traditional methods like RNNs and LSTMs. NLP is widely used across industries, but challenges such as language ambiguity, diversity, and ethical concerns remain.\",\n",
    "    \"Natural Language Processing (NLP) is a field of artificial intelligence that aims to enable computers to understand, interpret, and generate human language. NLP involves tasks like text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, automatic text summarization, and question answering systems. Traditional NLP techniques like Bag of Words and TF-IDF have been enhanced by word embeddings and Transformer models like BERT and GPT, which excel at understanding complex language patterns. NLP is utilized in various applications such as search engines, chatbots, healthcare, legal document analysis, and financial services, but faces challenges in dealing with language ambiguity, diversity, context understanding, and ethical biases. Despite these challenges, NLP continues to transform industries by improving human-computer interactions.\",\n",
    "    \"Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling machines to understand, interpret, and generate human language effectively. It combines computational linguistics, rule-based modeling, and machine learning to process natural language data. NLP tasks include text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, text summarization, and question answering systems. NLP techniques, such as Bag of Words, TF-IDF, and word embeddings like Word2Vec, have evolved with deep learning and Transformer models like BERT and GPT have revolutionized NLP applications. Despite challenges like language ambiguity and biases in training data, NLP is transforming industries by enhancing human-machine interaction.\",\n",
    "    \"Natural Language Processing (NLP) is an area of artificial intelligence that focuses on computers understanding and generating human language. NLP tasks include text preprocessing, syntactic and semantic analysis, language modeling for prediction, sentiment analysis, text summarization, and question answering systems. Techniques like Bag of Words, TF-IDF, word embeddings, and Transformer models like BERT and GPT have evolved to enhance NLP capabilities. Although NLP is widely used in various applications and industries, challenges such as language ambiguity, diversity, context understanding, and ethical concerns related to biases in data remain.\",\n",
    "    \"Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on computers' interaction with human language. NLP involves tasks like text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, text summarization, and question answering. Techniques in NLP have evolved from Bag of Words and TF-IDF to word embeddings like Word2Vec and advanced Transformer models like BERT and GPT, which excel at understanding complex language patterns. NLP is used in various applications, but faces challenges such as human language ambiguity, diversity of languages, context understanding, and ethical concerns regarding biases in training data. Despite challenges, NLP is revolutionizing industries by improving human-machine interactions.\",\n",
    "    \"Natural Language Processing (NLP) is a field of artificial intelligence that aims to facilitate communication between computers and humans using human language. It involves tasks such as text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, automatic text summarization, question answering systems, and more. NLP techniques have evolved, with Transformer models like BERT and GPT being widely used for tasks such as text generation and sentiment analysis. Despite challenges like language ambiguity and bias issues, NLP is making significant strides in various industries by enhancing human-computer interaction.\",\n",
    "    \"Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling computers to understand and generate human language. Techniques like text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, automatic text summarization, and question answering systems are used to process natural language data. Recent advancements in deep learning, particularly Transformer models like BERT and GPT, have revolutionized NLP by improving language understanding and performance in various tasks. Despite challenges such as language diversity and ethical concerns around bias, NLP is reshaping industries by enhancing human-machine interaction.\",\n",
    "    \"Natural Language Processing (NLP) is a field of artificial intelligence focused on computers interacting with humans using natural language. NLP involves tasks like text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, text summarization, and question answering systems. Techniques in NLP have evolved from basic methods like Bag of Words to more advanced models like Transformers, such as BERT and GPT, which excel at understanding complex language patterns. NLP is used in various applications, but faces challenges like language ambiguity, diversity, and ethical concerns around biases in training data. Despite challenges, NLP is transforming industries by enabling more intuitive interactions between machines and humans.\",\n",
    "    \"Natural Language Processing (NLP) is a field focused on computer-human interaction through human language, aiming to enable machines to understand and generate language effectively. It combines computational linguistics, rule-based modeling, and machine learning to process large amounts of text data. NLP tasks include text preprocessing, syntactic and semantic analysis, language modeling, sentiment analysis, automatic text summarization, and question answering systems. Recent advancements in deep learning, particularly Transformer models like BERT and GPT, have revolutionized NLP, replacing earlier models like RNNs and LSTMs. Despite challenges such as language diversity and ethical concerns regarding bias, NLP is widely used in various sectors like healthcare and finance, improving human-machine interactions significantly.\"\n",
    "]\n",
    "\n",
    "# Evaluate each summarizer\n",
    "results = {}\n",
    "for name, summarizer in summarizers.items():\n",
    "    print(f\"\\nEvaluating {name} summarizer...\")\n",
    "    rouge_2, rouge_l = evaluate_summarizer(summarizer, document, gpt_summaries)\n",
    "    results[name] = {'ROUGE-2': rouge_2, 'ROUGE-L': rouge_l}\n",
    "\n",
    "# Print results\n",
    "for name, scores in results.items():\n",
    "    print(f\"\\n{name} Summarizer:\")\n",
    "    print(f\"  ROUGE-2: {scores['ROUGE-2']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {scores['ROUGE-L']:.4f}\")\n",
    "\n",
    "# Analysis and comments\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"1. Performance Comparison:\")\n",
    "best_rouge2 = max(results, key=lambda x: results[x]['ROUGE-2'])\n",
    "best_rougel = max(results, key=lambda x: results[x]['ROUGE-L'])\n",
    "print(f\"   - Best ROUGE-2 performance: {best_rouge2}\")\n",
    "print(f\"   - Best ROUGE-L performance: {best_rougel}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
